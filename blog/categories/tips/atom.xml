<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: tips | @Lenciel]]></title>
  <link href="http://lenciel.cn/blog/categories/tips/atom.xml" rel="self"/>
  <link href="http://lenciel.cn/"/>
  <updated>2014-04-02T18:14:06+08:00</updated>
  <id>http://lenciel.cn/</id>
  <author>
    <name><![CDATA[Lenciel Li]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[解决iowait过高的告警]]></title>
    <link href="http://lenciel.cn/2014/02/hunting-the-iowait-problem-maker/"/>
    <updated>2014-02-24T09:22:00+08:00</updated>
    <id>http://lenciel.cn/2014/02/hunting-the-iowait-problem-maker</id>
    <content type="html"><![CDATA[<p><img src="/downloads/images/2014_02/warning_letter.png" alt="warning letter" title="Don't touch me..." /></p>

<p>从Nagios切到<a href="https://www.zabbix.com">Zabbix</a>之后，经常大清早被iowait过高的告警邮件叫醒。因为这套Zabbix监控是本座搭的，所以解决这个问题就只有本座来了…..哎，不知道是不是把首席运营官给宠坏了。</p>

<h2 id="iowait">iowait的定义和计算方式</h2>

<p>iowait的定义为：</p>

<p><blockquote><p>iowait is time that the processor/processors are waiting (i.e. is in an idle state and does nothing), during which there in fact was outstanding disk I/O requests.</p></blockquote></p>

<p>也就是至少有一个I/O在进行时CPU处于<code>idle</code>状态的比例。</p>

<p>我们都知道用<code>vmstat</code>, <code>iostat</code>, <code>sar</code>等命令查看系统状况的时候，CPU有四种比较主要的状态：user, sys, idle和iowait。它们都是表示CPU处于此状态的一个平均比例（其中sar命令是可以用<code>-P</code>具体指定哪个CPU的，其他的命令一般是所有CPU的平均），通常相加应该就是1.</p>

<p>这个比例的统计其实是通过kernel不断的更新计数器然后计算出来的。当时钟中断发生的时候，kernel检查当前CPU是不是idle的。如果不是，就检查正在执行的指令是user space还是kernel space的。如果是user space就给<code>user</code>的计数器加1，kernel space就给<code>sys</code>计数器加1.</p>

<p>类似的，如果CPU是处于idle状态，kernel就检查是不是有I/O操作正在发生（可以是local disk也可以是<code>mount</code>的NFS），如果有就给<code>iowait</code>计数器加1，没有就给<code>idle</code>计数器加1.</p>

<p>当我们运行<code>vmstat</code>或者<code>sar</code>等命令查看时，它们会先读取当前这几个计数器的计数，然后在用户指定的时间里面等待，然后再次读取。因为用户指定的时间里面过去了多少个<code>tick</code>是可以计算的，然后前后计数器的增值也可以计算，就可以算出一个比值。比如如果用户运行的命令是<code>vmstat 2</code>，表示每两秒取样一次，那么：</p>

<ol>
  <li>tick是10ms一个，所以总共是200个ticks</li>
  <li>计数器的增量/200*100就是每个状态的百分比</li>
</ol>

<h2 id="iowait-1">iowait的意义</h2>

<p>这其实比它怎么计算要难理解一些。比如本座之前心里就有一个疑问：既然只是某个process在block，那么系统会schedule其他的事情，这对性能有什么大不了的影响呢？</p>

<p>来看几个例子。</p>

<h3 id="section">例子一</h3>

<p>假设一个程序进行批量的事务，每个事务都有一个10ms的计算任务，计算出的结果通过同步的方式写到磁盘。由于它写结果的文件是阻塞方式打开的，所以I/O完成之前写操作是不会<code>return</code>的。如果我们假设磁盘系统没有cache，每个物理的I/O需要20ms，那么一个事务需要30ms。也就是每秒33个事务（33 tps）。如果把系统算成只有一个CPU的话，很显然<code>iowait</code>就是66%。</p>

<p>这种情况下，如果我们能改进I/O子系统，比如启用磁盘的缓存，让每次物理的I/O只需要1ms的话，那么<code>iowait</code>就会迅速下降到8%左右。可见这种情况下，<code>iowait</code>直接影响着程序的performance。</p>

<h3 id="section-1">例子二</h3>

<p>假设一个磁盘检查的程序运行在系统上，每秒钟读4k的数据。我们假设这个程序的入口是main()，然后读磁盘的函数是read()，main()和read()都是用户态的。read()属于libc.a，会调用kread()这个系统调用来进行物理的I/O，这个时候就进入了kernel态。整个main(),read()和kread执行的时间加起来不长，我们假设是50微秒。而物理的I/O需要多久要看seek的数据有多远，假设需要2-20ms。这样就完全有可能当时钟中断的时候，cpu是idle的，而且I/O正在发生，于是<code>iowait</code>值就达到97-98% (如果每个I/O需要20ms就是99-100%)。</p>

<p>这种情况下，虽然<code>iowait</code>数值非常高，其实这个系统的性能是正常的。</p>

<h3 id="section-2">例子三</h3>

<p>假设有两个程序跑在同一个CPU上。一个程序写得有点儿问题，I/O会阻塞10秒左右。另一个则100%的时间都在做计算。由于当前一个程序阻塞起来的时候，后面这个程序被运行了，因此无论什么时候都没有CPU处于idle的状态等I/O，于是<code>iowait</code>一直是0，这时候其实系统的performance是有很大的问题的。</p>

<h3 id="section-3">例子四</h3>

<p>假设系统是4核的CPU，运行了6个程序。其中4个程序有70%时间在进行物理的I/O，30%的时间在进行计算任务（假设其中25%在用户态，5%在kernel态）。另外2个程序假设100%时间都在用户态进行计算任务，没有任何I/O操作。</p>

<p>如果我们查看系统的CPU状态，大概可能看到下面的状况:</p>

<pre><code>     cpu    %usr    %sys    %iowait   %idle
      0       50      10      40       0
      1       50      10      40       0
      2      100       0       0       0
      3      100       0       0       0
      -       75       5      20       0
</code></pre>

<p>如果我们把相同的6个程序跑到一个6核的机器（相同的CPU和磁盘配置），那么可以简单的认为会有下面的结果：</p>

<pre><code>     cpu    %usr    %sys    %iowait   %idle
      0       25       5      70       0
      1       25       5      70       0
      2       25       5      70       0
      3       25       5      70       0
      4      100       0       0       0
      5      100       0       0       0
      -       50       3      47       0
</code></pre>

<p>也就是说，同样的程序跑在不同的系统上，iowait增加了一倍多，而这个时候其实没有什么performance问题，只不过是系统还能做更多的计算工作。</p>

<h3 id="section-4">结论</h3>

<ul>
  <li>CPU处于<code>iowait</code>状态，并不说明CPU不能运行其他的程序</li>
  <li><code>iowait</code>偏高只能说明系统这个时刻还能进行更多的计算任务，至于是不是出现了performance问题，需要进一步分析才知道</li>
</ul>

<h2 id="section-5">找出造成问题的进程</h2>

<p>虽然每次都是6点半多少说明应该是某个cron任务（因为机器上没有其他自定义的定时任务）但没法具体知道究竟是哪个。</p>

<p>最简单的办法当然是出问题的时候用<code>iotop</code>命令来看了 。</p>

<p><code>
 # iotop
 Total DISK READ: 8.00 M/s | Total DISK WRITE: 20.36 M/s
  TID PRIO USER DISK READ DISK WRITE SWAPIN IO&gt; COMMAND
 15758 be/4 root 7.99 M/s 8.01 M/s 0.00 % 61.97 % bonnie++ -n 0 -u 0 -r 239 -s 478 -f -b -d /tmp
</code></p>

<p>但是谁又会在6点多起来干这种事情。除开修改系统时间重现问题，还可以通过ps命令查看记录处于<code>D</code>状态的进程来找到。</p>

<p><code>ps</code>命令输出里面对<code>PROCESS STATE CODES</code>的定义是：</p>

<p><code>
 D uninterruptible sleep (usually IO)
 R running or runnable (on run queue)
 S interruptible sleep (waiting for an event to complete)
 T stopped, either by a job control signal or because it is being traced.
 W paging (not valid since the 2.6.xx kernel)
 X dead (should never be seen)
 Z defunct ("zombie") process, terminated but not reaped by its parent.
</code></p>

<p>处于等待I/O完成状态的进程一般就是<code>D</code>，所以可以通过tmux起一个sessio来跑下面的命令：</p>

<p><code>
	while true; do date; ps auxf | awk '{if($8=="D") print $0;}'; sleep 1; done &gt; /var/log/ps.log
</code></p>

<p>然后在又一个这样的6点半：</p>

<p><img src="/downloads/images/2014_02/zabbix_cpu_util.png" alt="warning letter" title="Don't touch me..." /></p>

<p>去日志里面查看：</p>

<p>```
$ cat /var/log/ps.log | grep D</p>

<p>root      7585  7.9  0.0   5904   812 ?        D    06:34   0:02                  _ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5904   812 ?        D    06:34   0:02                  _ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5904   812 ?        D    06:34   0:02                  _ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:02                  _ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:02                  _ /usr/bin/updatedb.mlocate
root      7585  7.5  0.0   5944   944 ?        D    06:34   0:02                  _ /usr/bin/updatedb.mlocate
root      7585  7.5  0.0   5944   944 ?        D    06:34   0:02                  _ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  _ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:04                  _ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  _ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  _ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  _ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  _ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:04                  _ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  _ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   6000   968 ?        D    06:34   0:04                  _ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   6000   968 ?        D    06:34   0:04                  _ /usr/bin/updatedb.mlocate
```</p>

<p>嗯，原来是<code>/usr/bin/updatedb.mlocate</code>。Google了一下<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup><sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>发现其实关掉也没什么：</p>

<p><code>
sudo killall updatedb.mlocate
sudo chmod -x /etc/cron.daily/mlocate
</code></p>

<p>整个世界清静了。</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>http://www.iasptk.com/ubuntuwp/can-i-disable-updatedb-mlocate/<a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>http://ubuntuforums.org/showthread.php?t=1243951&amp;page=2&amp;p=7844783#post7844783<a href="#fnref:2" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[定制机上恢复google原厂应用]]></title>
    <link href="http://lenciel.cn/2013/12/restore-google-apps/"/>
    <updated>2013-12-18T22:33:00+08:00</updated>
    <id>http://lenciel.cn/2013/12/restore-google-apps</id>
    <content type="html"><![CDATA[<p>最近因为移动的手机丢了，正好宽带升级到100M送了两个电信的卡没地方用，入了一个Rick推荐的电信移动双卡双待的机器：<a href="http://item.jd.com/824702.html">中兴N986</a>。</p>

<p>机器用来当小三机已经是非常不错了，唯一让本座纠结的就是电信的合约机老是喜欢把google账号干掉，而小弟的所有联系人又都在google（虽然现在看起来这么做可能也未必妥当）。</p>

<p>据Rick大大说，之前是可以用小米的<a href="http://app.xiaomi.com/detail/36925">谷歌应用下载器</a>来直接把Google的一干应用装回来。但是好像因为<a href="http://www.zhihu.com/question/21103129">Google不太愿意</a>自己的应用被未授权的雷总装来装去，这个应用已经没有更新了：青漾系统是4.2.1，下载回来的apk直接<code>adb install</code>会因为android版本不match报错。</p>

<p>于是只好去搜了<a href="http://www.teamandroid.com/gapps/">4.2.1的stock gapps包</a>回来自己撸 - <a href="http://pan.baidu.com/s/1iPXn">百度盘分享了一份</a>。</p>

<p>首先要root机器，然后把<code>/system/app</code>路径mount成rw的。</p>

<p>root就是刷recovery然后替换一些文件，当然大天朝有不少神器做得非常不错，比如<a href="http://www.mgyun.com/">刷机大师</a>这种软件，感觉会摧毁电脑城刷机青年的就业机会。而修改目录权限这种事情，如果你对命令行不熟，好像有很多流行的文件夹管理应用可以用来更改目录的权限。</p>

<p>然后，直接把下载回来的gapps.zip解压，进入<code>system/app</code>路径，将自己需要的apk往<code>/system/app</code>路径push就行了。</p>

<p>以Google联系人同步为例，就是：</p>

<p><code>bash
adb push GoogleContactsSyncAdapter.apk /system/app/.
</code></p>

<p>这里要注意的就是所有Google的应用有些基础的依赖，要记得check一下/system/app下面是不是都有，比如<code>GoogleServicesFramework.apk</code>等等。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Quick Look on Mac]]></title>
    <link href="http://lenciel.cn/2013/12/quick-look-on-mac/"/>
    <updated>2013-12-14T15:34:00+08:00</updated>
    <id>http://lenciel.cn/2013/12/quick-look-on-mac</id>
    <content type="html"><![CDATA[<p>Mac平台上，如果我们在Finder里面查看文件，有一个不太容易被察觉的方式是使用<a href="http://en.wikipedia.org/wiki/Quick_Look">Quick Look</a>：选中文件的情况下按<code>空格键</code>或者是<code>Cmd+Y</code>。速度快，疗效好，唯一的缺点就是有很多文件格式支持不佳，比如没有扩展名的config文件，比如各种markdown，比如图片等等。</p>

<p>最近在Github上看到一个<a href="https://github.com/sindresorhus/quick-look-plugins">Quick Look插件集中营</a>，非常不错的精选集，推荐也在用Quick Look的小伙伴们试试。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mac下后台运行goagent]]></title>
    <link href="http://lenciel.cn/2013/11/replace-goagentx-with-lines-of-scripts/"/>
    <updated>2013-11-14T13:22:00+08:00</updated>
    <id>http://lenciel.cn/2013/11/replace-goagentx-with-lines-of-scripts</id>
    <content type="html"><![CDATA[<p>几年过去了，<a href="https://code.google.com/p/goagent/">Goagent</a>是本座翻墙唯一的选择。在Mac上使用它最开始我用了<a href="https://github.com/ohdarling/GoAgentX">GoAgentX</a>，但使用了一段时间之后发现几个不太满意的地方：</p>

<ul>
  <li>不是简单给GoAgent做了个界面，而是集成了多个翻墙工具，选项挺多挺乱的（可能对其他用户是一个好事）</li>
  <li>每次GoAgent更新之后，GoAgentX更新的时间都比较滞后</li>
  <li>GoAgentX更新之后，经常无法工作，需要做这样那样的调整</li>
</ul>

<p>但其实用GoAgent我们需要的无非是<code>python proxy.py</code>，有很多办法让它运行起来。本座比较喜欢的是用tmux把这个任务跑在一个detach了的session，如果连接有问题再attach上去看看是什么问题。具体流程如下：</p>

<p>先装<a href="https://github.com/aziz/tmuxinator">tmuxinator</a>，看名字不知道是不是受了ubuntu下面terminator的启发。然后新建一个项目用来跑goagent:</p>

<p><code>bash
$ mux new goagent
</code></p>

<p>项目配置文件（假设你的goagent放在<code>~/bin/goagent/local</code>）：</p>

<p>```ruby
name: goagent
root: ~/bin/goagent/local</p>

<p>windows:
  - shell: python proxy.py
```</p>

<p>这样就只需要你在需要翻墙的时候<code>mux goagent</code>一下即可，detach或者attach到这个session也非常方便。当然不使用tmuxinator而是直接用shell脚本写一堆tmux命令也可以达到一样的效果，用tmuxinator是因为本座自己还有一堆别的Django项目的tmuxinator项目。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fix Python after upgrade to Maverick]]></title>
    <link href="http://lenciel.cn/2013/10/maverick-and-python/"/>
    <updated>2013-10-24T22:02:00+08:00</updated>
    <id>http://lenciel.cn/2013/10/maverick-and-python</id>
    <content type="html"><![CDATA[<p>升级到最新的osx版本Maverick之后，打开iTerm2就报错：</p>

<p><code>bash
Traceback (most recent call last):
  File "&lt;string&gt;", line 1, in &lt;module&gt;
ImportError: No module named virtualenvwrapper.hook_loader
virtualenvwrapper.sh: There was a problem running the initialization hooks.
If Python could not import the module virtualenvwrapper.hook_loader,
check that virtualenv has been installed for
VIRTUALENVWRAPPER_PYTHON=/usr/bin/python and that PATH is
set properly.
</code></p>

<p>敲pip之后也报错：</p>

<p><code>bash
Traceback (most recent call last):
  File "/usr/local/bin/pip", line 5, in &lt;module&gt;
    from pkg_resources import load_entry_point
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources.py", line 2603, in &lt;module&gt;
    working_set.require(__requires__)
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources.py", line 666, in require
    needed = self.resolve(parse_requirements(requirements))
  File "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources.py", line 565, in resolve
    raise DistributionNotFound(req)  # XXX put more info here
pkg_resources.DistributionNotFound: pip==1.3.1
</code></p>

<p>这坨<code>pkg_resources.DistributionNotFound</code>的错正好前两天装CentOS的机器<a href="http://stackoverflow.com/questions/7446187/no-module-named-pkg-resources">看到过</a>。</p>

<p>运行下面的命令更新了<code>setuptools</code>之后重装了<code>pip</code>和<code>virtualenv</code>、<code>virtualenvwrapper</code>就好了：</p>

<p><code>bash
wget https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py
sudo python ez_setup.py
sudo easy_install -U pip
</code></p>
]]></content>
  </entry>
  
</feed>
